{"cells":[{"cell_type":"code","source":"### Hunter Mitchell - 06/18/2020\n\n# Description: This code will predict the gender/age from a picture of someone. It is trained on 3000 images \n# from the imdb-wiki dataset and uses the CNN DenseNet-201\n\n\n\n#!pip install -q efficientnet\n\n\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom datetime import date\n\nimport cv2\nimport os\n\nfrom tensorflow.keras.applications import DenseNet201, DenseNet121\nfrom tensorflow.keras.models import load_model\nimport tensorflow.keras.layers as L\n\nfrom sklearn.model_selection import train_test_split\n\n#import efficientnet.tfkeras as efn\n\n\n\n\n\n\n############# SETTINGS ################\n\n\nprint(tf.__version__)\nprint(tf.keras.__version__)\n\n\nPREDICT_AGE = True\n\nTESTING = True\nTESTING_SIZE = 3000\n\nSEED = 2016\nIMG_SIZE = 256\n\nEPOCHS = 15\nBATCH_SIZE = 32\n\nLABELS_PATH = \"/kaggle/input/facelabels/faceLabels.csv\"\nIMAGES_PATH = \"/kaggle/input/faceimages/wiki_crop_stuff\"\nPRED_PIC_PATH = '/kaggle/input/predimages2/hunterpic05.jpg'\nPRED_PIC_PATH2 = '/kaggle/input/predimages/kyla.jpeg'\n\n\n############# FUNCTIONS ###############\n\n\n\ndef format_image(path):\n    img = cv2.imread(IMAGES_PATH + '/' + path)\n    img_new = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n    return img_new #/ 255.0\n    \n\ndef show_image(img):\n    new_img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    plt.imshow(new_img)\n    plt.show()\n\n\ndef reshape_list(old_list):\n    length = len(old_list)\n    new_list = [0]*length\n    for i in range(length):\n        new_list[i] = old_list[i]\n\n    new_list = np.asarray(new_list)\n    return new_list\n\n\n### learning rate schedule\ndef lrfn(epoch):\n    \n    lr_start=0.0001\n    lr_max=0.0003\n    lr_min=0.00001\n    lr_rampup_epochs=5\n    lr_sustain_epochs=2\n    lr_exp_decay=.7\n    \n    if epoch < lr_rampup_epochs:\n        lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n    elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n        lr = lr_max\n    else:\n        lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n    return lr\n\n\ndef get_gender_model():\n    \n    model = tf.keras.Sequential([\n        DenseNet201(\n            input_shape=(IMG_SIZE, IMG_SIZE, 3),\n            weights='imagenet',\n            include_top=False\n        ),\n        L.GlobalAveragePooling2D(),\n        L.Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(\n        optimizer='adam',\n        loss = 'binary_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    return model\n\n\n\ndef get_age_model():\n    \n    model = tf.keras.Sequential([\n        DenseNet121(\n            input_shape=(IMG_SIZE, IMG_SIZE, 3),\n            weights='imagenet',\n            include_top=False\n        ),\n        L.GlobalAveragePooling2D(),\n        L.Dense(1)\n    ])\n\n    model.compile(\n        optimizer='adam',\n        loss='mae',\n        metrics=['mae','mse']\n    )\n    \n    return model\n\n\n\n########## LOAD THE DATA ##############\n\n\n\n# from https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/\ndata = pd.read_csv(LABELS_PATH).sort_values(by='full_path').reset_index(drop=True)\n\nprint(data.head())\n#print(data.describe())\n\n\n\ntemp_pred_img = cv2.imread(PRED_PIC_PATH)\npred_img = cv2.resize(temp_pred_img,(IMG_SIZE,IMG_SIZE))\npred_img = pred_img.reshape(1,IMG_SIZE,IMG_SIZE,3) # for getting prediction\n\ntemp_pred_img2 = cv2.imread(PRED_PIC_PATH2)\npred_img2 = cv2.resize(temp_pred_img2,(IMG_SIZE,IMG_SIZE))\npred_img2 = pred_img2.reshape(1,IMG_SIZE,IMG_SIZE,3) # for getting prediction\n\n\n\n########## CLEAN AND PREPROCESS DATA ##########\n\n\n\n# get labels\nif (TESTING == True):\n    if (PREDICT_AGE == True):\n        train_labels = data[['dob','photo_taken']][:TESTING_SIZE]\n    else:\n        train_labels = data.gender[:TESTING_SIZE] # also data.dob or data.name\nelse :\n    if (PREDICT_AGE == TRUE):\n        train_labels = data[['dob','photo_taken']]\n    else:\n        train_labels = data.gender\n\n        \n\n        \n\n\n# preprocess age column, specify ages, and set up labels\nif (PREDICT_AGE == True):\n    \n    train_labels['photo_taken_date'] = train_labels.photo_taken.apply(lambda x: date.toordinal( date(x,7,1) ) )\n    train_labels['age_days'] = train_labels.photo_taken_date - train_labels.dob\n    train_labels['age'] = train_labels.age_days.apply(lambda x: int (x / 365))\n    train_labels = train_labels[ (train_labels.age >= 10) & (train_labels.age < 80) ]\n    #train_labels = train_labels.sort_values(by='age',ascending=False) # if I want df to be sorted ascending or descending\n    train_labels = train_labels.drop(['dob','photo_taken','photo_taken_date','age_days'],axis=1)\n\n\n\n\n# drop null values \nif (PREDICT_AGE == False):\n    \n    train_labels = train_labels.dropna()\n\n\n\n\n\n# get paths where there are labels\ntrain_paths = data.full_path[train_labels.index]\n\n\ntrain_paths = train_paths.reset_index(drop=True)\ntrain_labels = train_labels.reset_index(drop=True)\n\n\nprint(train_paths.describe())\nprint(train_labels.describe())\n\n\n\ntrain_images = train_paths.apply(format_image)\n\n\nprint(train_images.shape)\ntrain_images = reshape_list(train_images)\nprint(train_images.shape)\n\n\n\n\nprint(train_labels.head())\n#for i in range(5):\n#    show_image(train_images[i])\n\n\n\n#wait = input('PAUSING')\n\n\n\n\n# splitting data\ntrain_images,valid_images,train_labels,valid_labels = train_test_split(train_images,train_labels,test_size=0.15,random_state=SEED)\n\n\n\n\n########### DEFINE THE MODEL ################\n\n\n\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n\n\nif PREDICT_AGE == True:\n    model = get_age_model()\nelse:\n    model = get_gender_model()\n\n\nmodel.summary()\n\n\n\n######## TRAIN THE MODEL ##########\n\n\n\nhistory = model.fit(\n    train_images,\n    train_labels,\n    epochs=EPOCHS,\n    verbose=2,\n    callbacks=[lr_schedule],\n    #steps_per_epoch=STEPS_PER_EPOCH,\n    batch_size=BATCH_SIZE,\n    validation_data=(valid_images,valid_labels)\n)\n\n\n\n####### SAVE THE MODEL ###########\n\n\n#model.save('/kaggle/output/kaggle/working/current_model_kaggle')\nmodel.save('current_model_kaggle')\n\n\n\n\n\n\n# check predictions \n\nprediction = model.predict(pred_img)\n\nprint(prediction)\nshow_image(pred_img[0])\n\n\nprediction2 = model.predict(pred_img2)\n\nprint(prediction2)\nshow_image(pred_img2[0])\n\n\n\n\n\n### load model\n\n#model2 = load_model(\"/kaggle/working/current_model_kaggle\")\n\n\n#prediction = model2.predict(pred_img)\n\n#print(prediction)\n#show_image(pred_img[0])\n\n\n#prediction2 = model2.predict(pred_img2)\n\n#print(prediction2)\n#show_image(pred_img2[0])\n\n\n\n","metadata":{"collapsed":false,"_kg_hide-input":false},"execution_count":0,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}